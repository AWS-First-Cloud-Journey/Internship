# Worklog - Ngày 17/06/2025

## 📅 Thông tin cơ bản
- **Ngày**: 17/06/2025
- **Thứ**: Thứ ba
- **Tuần thực tập**: Tuần thứ 6/8
- **Thời gian làm việc**: 9:00 - 17:00
- **Mood**: 😊 stress vì ôn thi AIF

## 🎯 Mục tiêu ngày hôm nay
- [x] **Mục tiêu 1**: Học cách đánh giá các mô hình ML/AI cơ bản
- [x] **Mục tiêu 2**: Làm một phần của Lab Mastering LLM Evaluation - A Hands-On Bedrock and Promptfoo Workshop

## 💼 Công việc đã thực hiện

### 1. Nghiên cứu về đánh giá mô hình ML/AI ⏱️ 9:00 - 10:30
- **Mô tả**: Tìm hiểu các phương pháp và tiêu chí đánh giá mô hình ML/AI cơ bản, đặc biệt là các mô hình ngôn ngữ lớn (LLMs).
- **Kết quả**: Nắm vững các phương pháp đánh giá định lượng và định tính cho mô hình AI, các metrics phổ biến như perplexity, BLEU, ROUGE, và cách thức đánh giá con người đối với đầu ra của mô hình.
- **Tools/Tech**: Evaluation frameworks, Benchmarking tools, LLM evaluation metrics
- **Links**: N/A

### 2. Thực hành Lab về Amazon Bedrock và Promptfoo ⏱️ 10:30 - 12:00
- **Mô tả**: Làm một phần của Lab "Mastering LLM Evaluation - A Hands-On Bedrock and Promptfoo Workshop" để học cách đánh giá các mô hình ngôn ngữ lớn.
- **Kết quả**: Thiết lập được môi trường làm việc với Amazon Bedrock, hiểu cách sử dụng Promptfoo để đánh giá và so sánh hiệu suất của các mô hình khác nhau như Claude và Titan.
- **Tools/Tech**: Amazon Bedrock, Promptfoo, AWS Console, Foundation Models
- **Links**: https://catalog.us-east-1.prod.workshops.aws/promptfoo/en-US

## 📚 Kiến thức học được

### 🔧 Technical Skills
- **AWS Services**: 
	- Hiểu về Amazon Bedrock và cách sử dụng nó để đánh giá các mô hình ngôn ngữ lớn
	- Nắm vững cách thiết lập và sử dụng các mô hình như Claude và Titan trên Bedrock
	- Tìm hiểu cách tích hợp Amazon Bedrock với công cụ đánh giá như Promptfoo
- **Best Practices**: 
	- Hiểu các phương pháp đánh giá hiệu quả cho các mô hình ML/AI
	- Nắm được cách so sánh hiệu suất giữa các mô hình khác nhau
	- Áp dụng các tiêu chí đánh giá phù hợp với từng loại mô hình AI
- **Industry Knowledge**: 
	- Hiểu về các metrics đánh giá phổ biến trong ngành như perplexity, BLEU, ROUGE
	- Nắm vững các phương pháp đánh giá định lượng và định tính cho mô hình AI

### 💡 Concepts & Theory
- **New Concepts**: 
	- Các phương pháp đánh giá mô hình ML/AI cơ bản
	- Sự khác biệt giữa đánh giá định lượng và định tính cho LLMs
	- Các tiêu chí đánh giá đặc thù cho mô hình ngôn ngữ lớn
	- Công cụ benchmarking và evaluation frameworks
- **Best Practices**: 
	- Cách thiết lập môi trường đánh giá hiệu quả cho các mô hình AI
	- Phương pháp xây dựng bộ test cases để đánh giá mô hình toàn diện
	- Cân nhắc về độ chính xác và hiệu suất khi đánh giá các mô hình LLM
- **Industry Knowledge**: 
	- Xu hướng sử dụng các công cụ tự động hóa trong đánh giá mô hình AI
	- Các framework đánh giá phổ biến trong nghiên cứu và ứng dụng thực tế
	- Sự phát triển của các phương pháp đánh giá cho các mô hình ngôn ngữ

### 🤝 Soft Skills
- **Communication**: 
	- Hiểu về cách diễn đạt các khái niệm kỹ thuật phức tạp về AI
	- Cải thiện kỹ năng đọc hiểu tài liệu kỹ thuật về Generative AI và AWS
- **Problem Solving**: 
	- Phát triển khả năng xác định các use cases phù hợp cho Generative AI
	- Học cách tiếp cận có hệ thống với các công nghệ AI mới
- **Time Management**: 
	- Quản lý hiệu quả thời gian nghiên cứu các chủ đề phức tạp về AI
	- Phân bổ thời gian hợp lý cho việc học lý thuyết và tìm hiểu ứng dụng thực tế

## 🚧 Khó khăn và giải pháp: N/A

## 💭 Reflection & Insights

### What went well today?
- Hoàn thành đầy đủ các mục tiêu đã đề ra trong ngày, tập trung nghiên cứu về phương pháp đánh giá mô hình ML/AI và Amazon Bedrock.
- Hiểu rõ các phương pháp đánh giá mô hình ngôn ngữ lớn (LLMs) như các metrics perplexity, BLEU, ROUGE.
- Nắm vững cách thiết lập và sử dụng công cụ Promptfoo kết hợp với Amazon Bedrock để đánh giá hiệu suất các mô hình như Claude và Titan.
- Quản lý thời gian hiệu quả trong quá trình nghiên cứu các phương pháp đánh giá AI mới.

### What could be improved?
- Cần tìm hiểu thêm các ứng dụng thực tế của các phương pháp đánh giá mô hình ML/AI trong dự án cụ thể.
- Nên thực hành nhiều hơn với Amazon Bedrock để hiểu rõ cách triển khai và đánh giá các mô hình.
- Cần hoàn thành phần còn lại của Lab "Mastering LLM Evaluation" để có kiến thức toàn diện hơn.
- Tăng cường tương tác với mentor để nhận được hướng dẫn về phương pháp đánh giá mô hình AI hiệu quả.

### Key Insights
- Đánh giá mô hình AI là quá trình quan trọng đòi hỏi kết hợp cả phương pháp định lượng và định tính.
- Amazon Bedrock cung cấp một cách tiếp cận đơn giản để triển khai và đánh giá các mô hình AI phức tạp.
- Công cụ như Promptfoo giúp tự động hóa và chuẩn hóa quá trình đánh giá mô hình ngôn ngữ lớn.
- Việc thiết lập môi trường đánh giá đúng cách và xây dựng bộ test cases toàn diện là yếu tố quan trọng để đánh giá chính xác hiệu suất của các mô hình LLM.

### Questions & Curiosities: N/A

## 📋 Kế hoạch ngày mai

### Priority Tasks
- [] **High**: Tìm hiểu và khám phá các tính năng của Amazon Q Developer và các AI Dev Tool của AWS để hỗ trợ quá trình phát triển phần mềm
- [] **Medium**: N/A
- [] **Low**: N/A

## 📊 Self Assessment

### Productivity
- **Score**: 8/10
- **Reason**: Hoàn thành đầy đủ các mục tiêu đã đề ra trong ngày, bao gồm nghiên cứu về phương pháp đánh giá mô hình ML/AI và làm một phần lab với Amazon Bedrock và Promptfoo. Nắm vững được các metrics đánh giá phổ biến và hiểu rõ cách thiết lập môi trường đánh giá mô hình LLM.
- **Improvement**: Cần thực hành nhiều hơn với các công cụ đánh giá như Promptfoo và Amazon Bedrock. Nên áp dụng các phương pháp đánh giá vào các trường hợp cụ thể để hiểu sâu hơn.

### Learning
- **Score**: 8/10
- **New Knowledge**: Hiểu sâu về các phương pháp đánh giá mô hình ML/AI cơ bản, các metrics như perplexity, BLEU, ROUGE, sự khác biệt giữa đánh giá định lượng và định tính, và cách sử dụng Amazon Bedrock kết hợp với Promptfoo.
- **Application**: Có thể áp dụng kiến thức để thiết lập môi trường đánh giá hiệu quả cho các mô hình LLM, xây dựng bộ test cases toàn diện, và so sánh hiệu suất giữa các mô hình như Claude và Titan.

### Collaboration
- **Score**: 6/10
- **Interactions**: Chưa có nhiều tương tác với mentor trong quá trình nghiên cứu về phương pháp đánh giá mô hình ML/AI và thực hành với Amazon Bedrock.
- **Contributions**: N/A.

### Overall Satisfaction
- **Score**: 8/10
- **Highlights**: Nắm vững được các phương pháp và tiêu chí đánh giá mô hình ML/AI, đặc biệt là LLMs. Hiểu rõ cách thiết lập và sử dụng Amazon Bedrock và Promptfoo để đánh giá hiệu suất các mô hình.
- **Areas for Growth**: Cần hoàn thành phần còn lại của lab về đánh giá LLM, tìm hiểu thêm các ứng dụng thực tế của các phương pháp đánh giá, và tăng cường trao đổi với mentor để nhận được hướng dẫn chuyên sâu hơn.

## 📎 Attachments & Links

### Code & Projects: N/A

### Learning Resources: N/A

### Screenshots & Demos: N/A

---

**📝 Notes for tomorrow:** N/A

**🎯 Week Progress:** Hoàn thành ngày 2/5 trong tuần thứ 6.

---
*Worklog created by: Lê Minh Giàu*  
*Next review: 18/06/2025*
